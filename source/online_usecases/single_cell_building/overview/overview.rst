.. _scm_overview:

########
Overview
########

The Single Cell Building use cases show practical examples of how to obtain a single cell model of morphologically and biophysically detailed neurons exploiting the Blue Brain Python Optimization Library (BluePyOpt, Van Geit W et al., 2016, `Front. Neuroinform <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4896051/#>`_. 10:17. doi: `10.3389/fninf.2016.00017 <http://journal.frontiersin.org/article/10.3389/fninf.2016.00017/full>`_).

Although all use cases in this section use the current, public, version of the BluePyOpt, the different scientists implementing an optimization for a specific cell have used their own organization for the configuration files.

.. _hippocampal-neurons:

===================
Hippocampal neurons
===================

For the use cases referring to hippocampal cells, the different use cases will guide you through the most appropriate workflow, depending on what you would like to do. In general, they are organized around two different possibilities, of increasing complexity:

1) Rebuild an existing single cell model
2) Build your own cell model using HBP data

They differ in the amount and type of information you need to enter to configure and run an optimization. Below is a short description of all the files that are required to do an optimization run for hippocampal cells. In the simplest case, all the needed files will be automatically copied into your collab, and you just select items, push buttons, and wait to collect the results. In general, however, you may want to change something (initial parameters, channel distribution, electrophysiological features, etc). In this case you should of course know what you are doing.

To run the optimization, it is necessary to have a morphology, a set of mod files for the ion channel or special mechanism kinetics, the stimulation protocols to be used (typically step current clamp stimuli), and the electrophysiological features you would like to use as a reference for the optimization.

The above information is contained in four self-consistent JSON files. Self-consistency is ensured by starting all json files used for a specific optimization with the same string, as shown below.

**********
morph.json
**********
Defines the Neurolucida ASCII file containing the 3D reconstruction to be used for the optimization.
A typical file looks like:

.. code-block:: json

    {
	"INT_cAC_noljp": "011017HP2.asc"
    }

Where the first string is the optimization name, arbitrarily chosen by the user, and the second one is the name of the morphology file.

*************
features.json
*************
Contains the electrophysiological characteristics (spike event features, spike shape features, voltage features etc.) that will be used as a reference by the optimization process. In general, this file can be automatically generated by the eFEL GUI app. The different sections list the various features of interest.
A typical section looks like:

.. code-block:: json

    {
        "INT_cAC_noljp": {
       	    "step_-0.4": {
                "soma": {
                    "voltage_deflection": [-19.772462606879138,  2.0331488835160232],
                    "voltage_base": [-74.617595464571281,  2.1406043489404434 ]
                }
            }
    }

Again, the first string is the name of the optimization, and in this case the user was interested in optimizing the *voltage_deflection* and *voltage_base* measured at the soma under a somatic current injection of -0.4 nA.

**************
protocols.json
**************

Defines the stimulation protocols that should be used for the optimization. This file is also automatically created by the eFEL GUI app, and it is matched with the information contained in the **features.json** file.
A typical section looks like:

.. code-block:: json

    {
        "INT_cAC_noljp": {
       	    "step_-0.4": {
                "stimuli": [
                    {
                    	"delay": 531.0, 
                    	"amp": -0.4, 
                    	"duration": 400.0, 
                    	"totduration": 1131.0
                    }, 
                    {
                    	"delay": 0.0, 
                    	"amp": 0.0, 
                    	"duration": 1131.0, 
                    	"totduration": 1131.0
                    }
                ]
            }
    }

***************
parameters.json
***************

This is where a user can strongly determine the quality of the optimization. In this file, active and passive properties (and their distribution) are defined.

There are four self-explanatory main blocks defining: 1) the channels to be used in the different regions of a neuron (“mechanisms”), 2) their non-uniform distribution (“distributions”), 3) which parameter should be fixed (“fixed”) and 4) which parameters must be optimized (“optimized”).
Mechanism and parameter names of course depend on the set of mod files the user choose to equip the cell with.
A typical section looks like:

.. code-block:: json

    {
        "INT_cAC_noljp": {
       	    "mechanisms": {
        	"all":      ["pas","kdrb", "nax", "kap"],
        	"somatic":  ["kdb","kmb"],
        	"axonal":   ["kmb"],
        	"allnoaxon":["hd", "can", "cal", "cat", "kca", "cacumb","cagk"]
    	    },
    	    "distributions": {
    	    },
    	    "fixed": {
        	"global":    [["v_init", -80], ["celsius", 34]],
        	"all":       [["cm", 1, "secvar"],["ena", 50, "secvar"],["ek", -90, "secvar"]]
    	    },
    	    "optimized": {
                 "axonal": [
            	    ["gbar_nax", 0.025, 0.15, "uniform" ],
            	    ["gkdrbar_kdrb", 0.01, 0.08, "uniform" ],
                    ["gkabar_kap", 0.001, 0.04, "uniform" ],
                    ["gbar_kmb", 0.004, 0.05, "uniform" ],
                    ["Ra", 50, 300, "secvar"],
                    ["g_pas", 1e-6, 8e-5, "uniform" ],
                    ["e_pas", -95, -75, "uniform" ]
               ],
            }
        }
    }

The BluePyOpt must also be configured to set the search algorithm. This is done by defining the offspring size and the max number of generations.
Finally, these use cases require computing resources on a HPC system. In order to carry out the optimization a user must have an account on the Neuroscience Gateway or on one of the HPC systems supporting the Brain Simulation Platform activity, such as CINECA or JSC.

.. _neuroscience-gateway:

==========================
Neuroscience Gateway (NSG)
==========================

The Neuroscience Gateway (NSG) portal https://www.nsgportal.org/ facilitates access and use of National Science Foundation (NSF) High Performance Computing (HPC) resources by neuroscientists. Computational modeling of cells and networks has become an essential part of neuroscience research, and investigators are using models to address problems of ever increasing complexity, e.g. large scale network models and optimization or exploration of high dimensional parameter spaces. The NSG catalyzes such research by lowering or eliminating the administrative and technical barriers that currently make it difficult for investigators to use HPC resources. It offers free computer time to neuroscientists acquired via the supercomputer time allocation process managed by the Extreme Science and Engineering Discovery Environment (XSEDE) Resource Allocation Committee (XRAC). The portal provides access to the popular computational neuroscience tools installed on various HPC resources. It also provides a community mailing list for neuroscientists to collaborate and share ideas.

NSG can be accessed through a simple web portal or programmatically using RESTful services. The NSG provides an administratively and technologically streamlined environment for uploading models, specifying HPC job parameters, querying running job status, receiving job completion notices, and storing and retrieving output data. The NSG transparently distributes user's jobs to appropriate XSEDE HPC resources.

For the use cases referring to hippocampal cells, NSG will be accessed programmatically using RESTful services.

Successful job submission returns a message at each major processing point, as well as when problems are encountered. Each message has a timestamp, processing stage, and textual description. A job progresses through the following stages:
•	QUEUE - The job has been validated and placed in NSG's queue.
•	COMMANDRENDERING - The job has reached the head of the queue and NSG has created the command line that will be run.
•	INPUTSTAGING - NSG has created a temporary working directory for the job on the execution host and copied the input files over.
•	SUBMITTED - The job has been submited to the scheduler on the execution host.
•	LOAD_RESULTS - The job has finished running on the execution host and NSG has begun to transfer the results.
•	COMPLETED - Results successfully transferred and available.


S Sivagnanam, A Majumdar, K Yoshimoto, V Astakhov, A Bandrowski, M. E. Martone, and N. T. Carnevale. Introducing the Neuroscience Gateway, IWSG, volume 993 of CEUR Workshop Proceedings, CEUR-WS.org, 2013.
